WEBVTT

1
00:00:00.750 --> 00:00:06.260
Let's do an example now of a random
walk Metropolis-Hastings sampler for

2
00:00:06.260 --> 00:00:07.980
our continuous variable.

3
00:00:09.400 --> 00:00:14.360
Recall the model from the last segment
of lesson two where the data or

4
00:00:14.360 --> 00:00:17.830
the percentage change in total personnel

5
00:00:17.830 --> 00:00:21.450
from last year to this year for
ten companies.

6
00:00:22.800 --> 00:00:25.440
To remind us, I have the model right here.

7
00:00:27.660 --> 00:00:31.940
So yi represents the percent
change in personnel for

8
00:00:31.940 --> 00:00:36.820
company i, and given mu, the mean,

9
00:00:36.820 --> 00:00:41.400
each of these ys is
identically distributed and

10
00:00:41.400 --> 00:00:46.630
independent from this normal distribution
with mean mu and variance 1.

11
00:00:46.630 --> 00:00:53.627
Our prior distribution on mu is
the t-distribution with location 0,

12
00:00:53.627 --> 00:00:58.650
scale parameter 1 and
degrees of freedom 1.

13
00:00:58.650 --> 00:01:01.600
This is also referred to as
the co-sheet distribution.

14
00:01:03.130 --> 00:01:06.940
Because this model is not conjugate,

15
00:01:06.940 --> 00:01:11.980
the posterior distribution does not have
a standard form that we can easily sample.

16
00:01:13.370 --> 00:01:19.210
To get posterior samples, we're going
to need to setup a Markov chain,

17
00:01:19.210 --> 00:01:23.450
who's stationary distribution is
the posterior distribution we want.

18
00:01:24.960 --> 00:01:29.021
So, recall that the posterior
distribution has this form.

19
00:01:32.633 --> 00:01:36.370
We derived this expression for
the posterior in lesson two.

20
00:01:36.370 --> 00:01:39.550
The posterior distribution for

21
00:01:39.550 --> 00:01:43.920
mu is proportional to this
expression on the right.

22
00:01:43.920 --> 00:01:46.890
This function here will be our g of mu.

23
00:01:48.580 --> 00:01:50.980
The first thing we can do in R

24
00:01:50.980 --> 00:01:55.140
is to write a function that
will evaluate g of mu for us.

25
00:01:56.260 --> 00:02:00.040
Because posterior distributions
include likelihoods,

26
00:02:00.040 --> 00:02:03.730
which are the product of many
numbers that are potentially small,

27
00:02:03.730 --> 00:02:09.120
because they're like probabilities,
g of mu might evaluate to such

28
00:02:09.120 --> 00:02:15.390
a small number that the computer
treats it effectively as a zero.

29
00:02:15.390 --> 00:02:19.650
To avoid this problem, we're going
to work on the logarithmic scale

30
00:02:19.650 --> 00:02:21.980
which will be more numerically stable.

31
00:02:21.980 --> 00:02:27.550
So instead of computing this g function,
we're going to compute the log of g.

32
00:02:27.550 --> 00:02:34.276
If we take the log of this function,
we get this expression right here.

33
00:02:37.093 --> 00:02:41.315
So let's write this function in R,

34
00:02:41.315 --> 00:02:44.988
let's call it lg for the log of g

35
00:02:47.067 --> 00:02:52.510
It'll be a function and
it will take three different arguments.

36
00:02:52.510 --> 00:02:57.510
We need to have y bar,
we need to enter n, and

37
00:02:57.510 --> 00:03:01.390
we need to enter a value for
mu for this function to evaluate.

38
00:03:02.580 --> 00:03:05.873
So we need mu, n and y bar.

39
00:03:08.893 --> 00:03:13.290
Just like with a for loop, we need curly
braces when we're defining a function.

40
00:03:15.600 --> 00:03:19.285
Okay, the first thing we'll
calculate is mu squared and

41
00:03:19.285 --> 00:03:23.770
we're going to call it mu 2 as
a variable inside this function.

42
00:03:23.770 --> 00:03:25.647
It's just the square of mu.

43
00:03:27.992 --> 00:03:32.696
Then we'll output this

44
00:03:32.696 --> 00:03:38.106
expression right here, so

45
00:03:38.106 --> 00:03:44.221
it needs to be n*(ybar*mu-

46
00:03:44.221 --> 00:03:48.700
mu2 divided by 2).

47
00:03:48.700 --> 00:03:53.360
Let's actually space these out
a little bit so it's easier to read.

48
00:03:53.360 --> 00:04:00.374
Minus the log(1.0+mu2).

49
00:04:00.374 --> 00:04:06.898
This completes the log of g function and
we can read this in to our R console.

50
00:04:08.477 --> 00:04:12.953
Next, let's write a function to execute
the random walk Metropolis-Hasting

51
00:04:12.953 --> 00:04:13.563
sampler.

52
00:04:13.563 --> 00:04:18.370
And we're going to use normal
proposal distributions to do this.

53
00:04:19.690 --> 00:04:21.140
As we write the function,

54
00:04:21.140 --> 00:04:25.509
let's take a look at the algorithm
here to remind us how it goes.

55
00:04:27.040 --> 00:04:31.057
I'm going to call this function mh for
Metropolis-Hastings.

56
00:04:32.270 --> 00:04:35.470
We need a few more
arguments in this function.

57
00:04:35.470 --> 00:04:42.105
First, we need a couple of the arguments
from before and the sample size.

58
00:04:42.105 --> 00:04:45.590
y bar which is the sample mean of y.

59
00:04:45.590 --> 00:04:49.940
We need to choose how many iterations
we're going to run this sampler for.

60
00:04:49.940 --> 00:04:56.520
So I'll call that n_iter,
that represents how many iterations.

61
00:04:58.090 --> 00:05:00.620
We need an initial value for mu.

62
00:05:02.220 --> 00:05:03.950
We'll call that mu_init.

63
00:05:03.950 --> 00:05:08.840
And finally,
we need a standard deviation for

64
00:05:08.840 --> 00:05:12.450
the candidate generating
normal distribution.

65
00:05:12.450 --> 00:05:15.540
So let's call that candidate
standard deviation.

66
00:05:17.690 --> 00:05:19.808
These are the arguments we'll
need in our function here.

67
00:05:22.014 --> 00:05:29.760
Okay, so first, we need to do step 1
which is to set up an initial value.

68
00:05:29.760 --> 00:05:30.810
Before we do that,

69
00:05:30.810 --> 00:05:36.975
let's initialize a vector of mu values
that we will output with this function.

70
00:05:36.975 --> 00:05:43.785
So mu out will get a numeric
vector with n.iter entries.

71
00:05:43.785 --> 00:05:49.015
It's useful with the Metropolis-Hastings
algorithm to keep track of how often

72
00:05:49.015 --> 00:05:51.415
our candidates get accepted.

73
00:05:51.415 --> 00:05:53.599
So let's create a variable called accept.

74
00:05:56.106 --> 00:05:58.215
And we'll initialize it as 0.

75
00:06:00.300 --> 00:06:05.690
Now as we iterate through, we're going
to be updating our value for mu.

76
00:06:07.190 --> 00:06:09.430
As we update it we need
to store it somewhere.

77
00:06:09.430 --> 00:06:12.784
Let's call that mu_now.

78
00:06:14.630 --> 00:06:20.476
And we'll initialize it as the first
value, the initial value for mu.

79
00:06:20.476 --> 00:06:28.099
We also need a current value for
the log of g function, lg_now.

80
00:06:32.697 --> 00:06:37.140
This is going to be an evaluation
of the lg function.

81
00:06:38.360 --> 00:06:42.550
So we need to give it three arguments,
mu, which will be mu_now, n,

82
00:06:45.440 --> 00:06:51.350
which is always just n and
we'll need to give it y-bar.

83
00:06:51.350 --> 00:06:55.730
This completes step one of
setting initial values and

84
00:06:55.730 --> 00:07:00.617
initializing a random work
Metropolis-Hasting sampler.

85
00:07:00.617 --> 00:07:03.720
So now let's move on to step two

86
00:07:03.720 --> 00:07:07.980
where we need to repeat
the following steps many times.

87
00:07:07.980 --> 00:07:10.308
This means we are going to do it in a for
loop.

88
00:07:10.308 --> 00:07:15.385
So for i will iterate over the variable i,

89
00:07:15.385 --> 00:07:22.205
in 1, 2 n_iter,
that's our number of iterations,

90
00:07:22.205 --> 00:07:26.430
we're going to do the following.

91
00:07:28.110 --> 00:07:32.450
The first thing we need to
do is draw a candidate for

92
00:07:32.450 --> 00:07:36.110
our parameter mu from
a proposal distribution.

93
00:07:37.640 --> 00:07:40.790
So let's draw mu candidate.

94
00:07:40.790 --> 00:07:43.788
We'll call our variable mu candidate.

95
00:07:43.788 --> 00:07:47.890
And it'll be a draw from
a normal distribution, rnorm.

96
00:07:47.890 --> 00:07:52.960
We'll take a single draw
where the mean of this

97
00:07:52.960 --> 00:07:57.510
distribution is the current value of mu.

98
00:07:57.510 --> 00:08:04.360
And the standard deviation is
the candidate standard deviation.

99
00:08:05.400 --> 00:08:07.540
So this is where we'll draw the candidate.

100
00:08:09.040 --> 00:08:13.438
The second step in the Metropolisâ€“Hastings
algorithm is to compute

101
00:08:13.438 --> 00:08:14.967
the acceptance ratio.

102
00:08:17.661 --> 00:08:21.581
In our case, the candidate
generating distribution is normal,

103
00:08:21.581 --> 00:08:23.780
which is symmetric.

104
00:08:23.780 --> 00:08:26.950
So these queue distributions

105
00:08:26.950 --> 00:08:31.010
in the Metropolis-Hastings ratio
will cancel each other out.

106
00:08:31.010 --> 00:08:35.830
So the ratio will actually
be g evaluated at

107
00:08:35.830 --> 00:08:40.570
the candidate divided by g
evaluated at the old value.

108
00:08:42.280 --> 00:08:45.930
For numerical stability,
we will calculate this on the log scale.

109
00:08:47.620 --> 00:08:53.490
So the first thing we want to do is get
the log of g evaluated at the candidate.

110
00:08:53.490 --> 00:08:57.310
So lg using our candidate
that we just drew.

111
00:08:59.425 --> 00:09:04.407
To do this we will call our
lg function again where

112
00:09:04.407 --> 00:09:08.790
mu is now going to be
equal to mu candidate.

113
00:09:12.377 --> 00:09:17.040
Again, n will equal n and
y bar will be y bar.

114
00:09:18.270 --> 00:09:23.120
We now have the log of g evaluated for
the candidate draw.

115
00:09:23.120 --> 00:09:28.210
We now need it for
the log of g evaluated at the last value.

116
00:09:28.210 --> 00:09:32.670
But we already have that, tt's lg_now.

117
00:09:32.670 --> 00:09:36.350
So we are now ready to calculate alpha,
the acceptance ratio.

118
00:09:36.350 --> 00:09:41.200
Of course we've done this on the log
scale so let's call this log alpha.

119
00:09:43.370 --> 00:09:49.717
And it equals lg evaluated
at the candidate minus lg,

120
00:09:49.717 --> 00:09:56.010
the current lg, lg_now,
this is the log of alpha.

121
00:09:56.010 --> 00:09:59.592
So to get the real alpha,
we just need to exponentiate it

122
00:10:06.349 --> 00:10:10.570
Now that we've calculated alpha,
we're ready to move on to step c here.

123
00:10:13.010 --> 00:10:17.380
So the first thing we're going to do
is draw from the uniform distribution.

124
00:10:17.380 --> 00:10:19.246
We'll save it in the variable called u.

125
00:10:22.729 --> 00:10:29.382
Runit(1) that takes a draw for
the uniform distribution between 0 and 1.

126
00:10:29.382 --> 00:10:36.499
Then, if, u is less than alpha,

127
00:10:36.499 --> 00:10:42.125
that gives us an event that
happens with probability alpha,

128
00:10:42.125 --> 00:10:46.620
then we're going to do the following.

129
00:10:46.620 --> 00:10:51.130
With probability alpha,
we're going to accept the candidate.

130
00:10:51.130 --> 00:10:58.680
In other words, mu_now, the current
iteration of mu will become mu candidate.

131
00:11:01.480 --> 00:11:06.710
We also want to keep track of how
often we are accepting the candidates.

132
00:11:06.710 --> 00:11:12.798
So let's add 1 to the acceptance count.

133
00:11:17.142 --> 00:11:20.672
Since we accepted the candidate,

134
00:11:20.672 --> 00:11:27.010
we need to update lg_now to be
lg evaluated at the candidate.

135
00:11:28.610 --> 00:11:33.830
Finally, within this loop,
we need to collect to save our results.

136
00:11:33.830 --> 00:11:37.790
So let's put this in, mu_out.

137
00:11:37.790 --> 00:11:41.604
This is the vector that we initialized
at the beginning of the function.

138
00:11:41.604 --> 00:11:47.292
So, the ith entry of mu_out

139
00:11:47.292 --> 00:11:52.300
is going to get mu_now.

140
00:11:52.300 --> 00:11:57.520
Finally, we need to determine what our
function is going to return at the end.

141
00:11:58.960 --> 00:12:04.320
What we need are our samples from
the Metropolis-Hastings sampler.

142
00:12:04.320 --> 00:12:05.970
So we need to output mu_out.

143
00:12:05.970 --> 00:12:13.570
And it would be helpful also to
output our final acceptance count.

144
00:12:13.570 --> 00:12:17.000
We can have a function return
multiple outputs through a list.

145
00:12:18.240 --> 00:12:21.960
So the last line of the function
will include a list

146
00:12:21.960 --> 00:12:23.610
where we're going to output two things.

147
00:12:24.780 --> 00:12:30.650
mu, which will be our vector, mu.out.

148
00:12:30.650 --> 00:12:34.950
That contains all our samples from
the Metropolis-Hastings sampler.

149
00:12:34.950 --> 00:12:37.940
And then we'll return the accept rate.

150
00:12:40.360 --> 00:12:43.740
So it'll be our acceptance count,
accpt, that

151
00:12:45.270 --> 00:12:50.330
counts how many acceptances we had,
divided by the number of iterations.

152
00:12:51.390 --> 00:12:53.300
That gives us the acceptance rate.

153
00:12:55.080 --> 00:12:58.750
This completes our function for
the Metropolis-Hastings sampler.