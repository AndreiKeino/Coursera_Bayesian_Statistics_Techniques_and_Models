WEBVTT

1
00:00:00.000 --> 00:00:03.797
[MUSIC]

2
00:00:03.797 --> 00:00:09.015
We now have experience fitting regression
models when the response is continuous,

3
00:00:09.015 --> 00:00:10.420
and when it is binary.

4
00:00:11.560 --> 00:00:13.430
What about when we have count data?

5
00:00:14.480 --> 00:00:21.340
We could fit a linear normal regression,
but here we have a couple of drawbacks.

6
00:00:21.340 --> 00:00:25.180
First of all,
counts usually aren't negative.

7
00:00:25.180 --> 00:00:28.412
And the variances might not be constant.

8
00:00:28.412 --> 00:00:32.720
The Poisson distribution provides
a natural likelihood for count data.

9
00:00:33.820 --> 00:00:38.460
We can write the basic model, as yi,

10
00:00:38.460 --> 00:00:44.599
given lambda i,
is independent from the Poisson

11
00:00:44.599 --> 00:00:49.254
distribution, with mean lambda i.

12
00:00:53.279 --> 00:00:57.740
Here, lambda conveniently
represents the expected value of y.

13
00:00:58.740 --> 00:01:02.700
It turns out that lambda
is also the variance of y.

14
00:01:02.700 --> 00:01:05.560
So if we expect a count to be higher,

15
00:01:05.560 --> 00:01:08.710
we also expect the variability
in counts to go up.

16
00:01:09.710 --> 00:01:12.470
We saw this earlier with
the warp breaks data.

17
00:01:15.040 --> 00:01:18.672
If we model the mean directly,
like we did with linear regression.

18
00:01:24.819 --> 00:01:32.195
That is, we had the expected value yi was
directly modelled with this linear form.

19
00:01:33.938 --> 00:01:38.700
We would run into the same problem
we did with logistic regression.

20
00:01:38.700 --> 00:01:43.260
The expected value has to be greater
than zero in the Poisson distribution.

21
00:01:44.630 --> 00:01:47.560
To naturally deal with that restriction,

22
00:01:47.560 --> 00:01:51.170
we're going to use
the logarithmic link function.

23
00:01:51.170 --> 00:01:52.150
So, the log link.

24
00:01:54.720 --> 00:02:02.271
That is, that the log of lambda i is
equal to this linear piece right here.

25
00:02:07.389 --> 00:02:12.030
From this, we can easily recover
the expression for the mean itself.

26
00:02:13.220 --> 00:02:18.390
That is, we can invert this link function
to get the expected value of yi,

27
00:02:18.390 --> 00:02:24.970
which just happens to be lambda i,
which is e to the beta not

28
00:02:24.970 --> 00:02:30.960
plus beta 1x 1i.

29
00:02:30.960 --> 00:02:34.640
It might seem like this model is
equivalent to fitting a normal linear

30
00:02:34.640 --> 00:02:36.640
regression to the log of y.

31
00:02:37.920 --> 00:02:40.610
But there are a few key differences.

32
00:02:40.610 --> 00:02:45.220
In the normal regression, we're modeling
the mean of the response directly.

33
00:02:45.220 --> 00:02:47.717
So we would be fitting
a model to the log of y.

34
00:02:47.717 --> 00:02:52.430
Where we're modeling the expected
value of the log of y.

35
00:02:54.750 --> 00:02:57.152
This is different from
what we're modeling here,

36
00:02:57.152 --> 00:03:02.380
here we're doing the log
of the expected value of y.

37
00:03:04.780 --> 00:03:08.760
These are not equal, they're usually
similar, but they're not the same.

38
00:03:09.810 --> 00:03:14.390
Another difference is that we have
a separate independent parameter for

39
00:03:14.390 --> 00:03:17.020
the variants in a normal regression.

40
00:03:18.370 --> 00:03:22.870
In Poisson regression, the variance
is automatically the same as lambda,

41
00:03:22.870 --> 00:03:26.730
which may not always be appropriate,
as we'll see in an upcoming example.

42
00:03:28.510 --> 00:03:29.230
As usual,

43
00:03:29.230 --> 00:03:34.450
we can add more explanatory x variables
to the Poisson regression framework.

44
00:03:34.450 --> 00:03:39.807
They can be continuous, categorical,
or they could be counts themselves.

45
00:03:39.807 --> 00:03:45.539
[MUSIC]